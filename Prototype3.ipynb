{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to transform our labels data set into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each label file in the labels folder\n",
    "def create_csv_annotations(images_folder, labels_folder, name):\n",
    "    annotations = []\n",
    "    image_width = 224\n",
    "    image_height = 224\n",
    "\n",
    "    for label_file in os.listdir(labels_folder):\n",
    "        if label_file.endswith('.txt'):\n",
    "            with open(os.path.join(labels_folder, label_file), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            image_name = os.path.splitext(label_file)[0] + '.jpg'\n",
    "            image_path = os.path.join(images_folder, image_name)\n",
    "            \n",
    "            for line in lines:\n",
    "                class_label, x_center, y_center, width, height = map(float, line.split())\n",
    "                x_min = (x_center - width / 2)\n",
    "                y_min = (y_center - height / 2)\n",
    "                x_max = (x_center + width / 2)\n",
    "                y_max = (y_center + height / 2)\n",
    "                \n",
    "                annotations.append([image_path, x_min, y_min, x_max, y_max, image_width, image_height, class_label])\n",
    "\n",
    "        # Here we create a DataFrame from annotations list and then we convert the df into a csv file\n",
    "        df = pd.DataFrame(annotations, columns=['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'width', 'height', 'label'])\n",
    "        df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/train', 'labels/train', 'annotations_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/test', 'labels/test', 'annotations_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/val', 'labels/val', 'annotations_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensor flow intro -> Why sequential](https://towardsdatascience.com/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa#:~:text=The%20sequential%20model%20allows%20us,for%20building%20deep%20learning%20models.)\n",
    "\n",
    "[Input and output shapes for CNN](https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca)\n",
    "\n",
    "[Basics of the R-CNN model](https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from CSV\n",
    "train_annotations = pd.read_csv('annotations_train.csv')\n",
    "val_annotations = pd.read_csv('annotations_val.csv')\n",
    "test_annotations = pd.read_csv('annotations_test.csv')\n",
    "\n",
    "#train_annotations, val_annotations = train_test_split(annotations, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_shape = (224, 224, 3)  # height, width, depth (this is the # of color channels RGB = 3)\n",
    "\n",
    "# Function to preprocess image and annotations -> this is because \n",
    "# the annotations are still not in the format required for TF\n",
    "def preprocess_data(annotation):\n",
    "    image = load_img(annotation['img_path'], target_size=(input_shape[0], input_shape[1]))\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    bbox = [annotation['xmin'], annotation['ymin'], annotation['xmax'], annotation['ymax']]\n",
    "    label = annotation['label']\n",
    "    return image_array, bbox, label\n",
    "\n",
    "train_data = train_annotations.apply(preprocess_data, axis=1)\n",
    "val_data = val_annotations.apply(preprocess_data, axis=1)\n",
    "test_data = test_annotations.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Convert preprocessed data into arrays -> this is the format needed for TF\n",
    "X_train, y_train_bbox, y_train_label = zip(*train_data)\n",
    "X_val, y_val_bbox, y_val_label = zip(*val_data)\n",
    "X_test, y_test_bbox, y_test_label = zip(*test_data)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train_bbox = tf.convert_to_tensor(y_train_bbox)\n",
    "y_train_label = tf.convert_to_tensor(y_train_label)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "y_val_bbox = tf.convert_to_tensor(y_val_bbox)\n",
    "y_val_label = tf.convert_to_tensor(y_val_label)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test_bbox = tf.convert_to_tensor(y_test_bbox)\n",
    "y_test_label = tf.convert_to_tensor(y_test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2776"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2776, 224, 224, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([859])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2776,), dtype=float32, numpy=array([3., 3., 3., ..., 2., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(859,), dtype=float32, numpy=\n",
       "array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2., 4., 1., 1., 4.,\n",
       "       1., 1., 4., 1., 2., 3., 4., 4., 3., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       3., 2., 4., 4., 2., 2., 2., 4., 4., 4., 4., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 3., 3., 3., 2., 2., 2., 1., 1., 4., 4., 3., 3., 3., 2., 2., 4.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2., 3., 3., 1., 1., 2.,\n",
       "       2., 3., 3., 3., 2., 3., 3., 4., 4., 4., 1., 1., 1., 4., 1., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 3., 3., 2., 2., 3., 3., 2., 2., 3., 3.,\n",
       "       3., 3., 3., 4., 1., 1., 4., 4., 0., 1., 4., 1., 1., 0., 3., 2., 2.,\n",
       "       3., 2., 3., 2., 1., 0., 0., 1., 0., 1., 1., 0., 2., 3., 3., 2., 2.,\n",
       "       2., 4., 4., 2., 3., 1., 2., 3., 3., 3., 3., 3., 3., 3., 3., 2., 2.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "       2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 2., 3., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 3., 2., 2., 2., 2., 1., 1., 1., 1.,\n",
       "       3., 2., 2., 3., 2., 2., 2., 3., 3., 3., 3., 1., 1., 1., 1., 2., 2.,\n",
       "       2., 2., 3., 3., 3., 2., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 1.,\n",
       "       1., 1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 2., 1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 2., 2., 2.,\n",
       "       2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1.,\n",
       "       1., 1., 2., 2., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1.,\n",
       "       1., 1., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       2., 2., 1., 3., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2.,\n",
       "       2., 1., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 2., 2., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1.,\n",
       "       1., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 3., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 2., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 2., 2., 2., 1., 1., 1., 1., 1., 1., 2., 2., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 2., 2., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the RCNN model, this is just base model for testing\n",
    "def create_rcnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),#batch_input_shape (if you wanted to give the batch_size)\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(), # Here we are basically changing the 4D output of the CNN to 2D so that we can use Dense\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax', name='classifier_output')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Number of classes\n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "# Create an instance of the R-CNN model\n",
    "rcnn_model = create_rcnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with appropriate losses and metrics\n",
    "rcnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "rcnn_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCNN With MovileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "87/87 [==============================] - 277s 3s/step - loss: 0.7821 - accuracy: 0.7003 - val_loss: 1.1293 - val_accuracy: 0.6752\n",
      "Epoch 2/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.6065 - accuracy: 0.7720 - val_loss: 0.9024 - val_accuracy: 0.6822\n",
      "Epoch 3/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.6084 - accuracy: 0.7622 - val_loss: 3.2185 - val_accuracy: 0.1281\n",
      "Epoch 4/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.5777 - accuracy: 0.7741 - val_loss: 1.2873 - val_accuracy: 0.2352\n",
      "Epoch 5/15\n",
      "87/87 [==============================] - 260s 3s/step - loss: 0.5349 - accuracy: 0.7878 - val_loss: 1.9865 - val_accuracy: 0.2421\n",
      "Epoch 6/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.5108 - accuracy: 0.7947 - val_loss: 3.5161 - val_accuracy: 0.3725\n",
      "Epoch 7/15\n",
      "87/87 [==============================] - 256s 3s/step - loss: 0.5183 - accuracy: 0.7918 - val_loss: 0.9597 - val_accuracy: 0.6694\n",
      "Epoch 8/15\n",
      "87/87 [==============================] - 270s 3s/step - loss: 0.5351 - accuracy: 0.7932 - val_loss: 1.0858 - val_accuracy: 0.5588\n",
      "Epoch 9/15\n",
      "87/87 [==============================] - 270s 3s/step - loss: 0.5175 - accuracy: 0.7885 - val_loss: 3.3442 - val_accuracy: 0.2875\n",
      "Epoch 10/15\n",
      "87/87 [==============================] - 249s 3s/step - loss: 0.4931 - accuracy: 0.7929 - val_loss: 3.3598 - val_accuracy: 0.1153\n",
      "Epoch 11/15\n",
      "87/87 [==============================] - 251s 3s/step - loss: 0.5413 - accuracy: 0.7885 - val_loss: 1.5074 - val_accuracy: 0.2887\n",
      "Epoch 12/15\n",
      "87/87 [==============================] - 247s 3s/step - loss: 0.4938 - accuracy: 0.8015 - val_loss: 1.4249 - val_accuracy: 0.1804\n",
      "Epoch 13/15\n",
      "87/87 [==============================] - 245s 3s/step - loss: 0.4745 - accuracy: 0.7983 - val_loss: 0.8281 - val_accuracy: 0.6787\n",
      "Epoch 14/15\n",
      "87/87 [==============================] - 246s 3s/step - loss: 0.4624 - accuracy: 0.8069 - val_loss: 1.0161 - val_accuracy: 0.5565\n",
      "Epoch 15/15\n",
      "87/87 [==============================] - 245s 3s/step - loss: 0.4389 - accuracy: 0.8102 - val_loss: 0.8252 - val_accuracy: 0.7218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x140f2773400>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_rcnn_MovileNetV2(input_shape, num_classes):\n",
    "    \n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    \n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Additional convolutional layers with reduced kernel size\n",
    "    conv_layers = models.Sequential([ #Without the padding / strides I get dimensionality errors :(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),  # Reduce the pooling stride\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),  # Reduce the pooling stride\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "    ])\n",
    "    \n",
    "    # R-CNN top layers\n",
    "    top_layers = models.Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax', name='classifier_output')\n",
    "    ])\n",
    "    \n",
    "    # Combine the base ResNet model, additional convolutional layers, and top layers\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        conv_layers,\n",
    "        top_layers\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Number of classes\n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "input_shape = (224, 224, 3)  # 224 is the one used by ResNet\n",
    "rcnn_resnet_model = create_rcnn_MovileNetV2(input_shape, num_classes)\n",
    "\n",
    "rcnn_resnet_model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rcnn_resnet_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 7s 525ms/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Vehiculos       0.00      0.00      0.00         3\n",
      "Construcciones       0.80      0.93      0.86       254\n",
      "          Vias       0.73      0.39      0.51        98\n",
      "          Rios       0.67      0.83      0.74        60\n",
      "       Mineria       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.77       424\n",
      "     macro avg       0.44      0.43      0.42       424\n",
      "  weighted avg       0.74      0.77      0.74       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   3   0]\n",
      " [  0 237   5  12   0]\n",
      " [  0  55  38   5   0]\n",
      " [  0   3   7  50   0]\n",
      " [  0   2   2   5   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(rcnn_resnet_model.predict(X_val), axis=1)\n",
    "\n",
    "y_val_label = np.array(y_val_label, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "target_names = ['Vehiculos', 'Construcciones', 'Vias', 'Rios', 'Mineria']  # Get unique class labels\n",
    "print(classification_report(y_val_label, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_label, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 392s 4s/step - loss: 0.8008 - accuracy: 0.7082 - val_loss: 0.5171 - val_accuracy: 0.7939\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 369s 4s/step - loss: 0.5806 - accuracy: 0.7677 - val_loss: 0.4816 - val_accuracy: 0.8044\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 373s 4s/step - loss: 0.5310 - accuracy: 0.7914 - val_loss: 0.5054 - val_accuracy: 0.8079\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 373s 4s/step - loss: 0.5063 - accuracy: 0.7968 - val_loss: 0.4566 - val_accuracy: 0.8091\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 371s 4s/step - loss: 0.4873 - accuracy: 0.7979 - val_loss: 0.4525 - val_accuracy: 0.8102\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 372s 4s/step - loss: 0.4576 - accuracy: 0.8030 - val_loss: 0.4564 - val_accuracy: 0.7986\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 371s 4s/step - loss: 0.4548 - accuracy: 0.8098 - val_loss: 0.4470 - val_accuracy: 0.8114\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 371s 4s/step - loss: 0.4509 - accuracy: 0.8062 - val_loss: 0.4415 - val_accuracy: 0.8114\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 374s 4s/step - loss: 0.4480 - accuracy: 0.8105 - val_loss: 0.4328 - val_accuracy: 0.8137\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 373s 4s/step - loss: 0.4358 - accuracy: 0.8134 - val_loss: 0.4413 - val_accuracy: 0.8114\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " sequential_11 (Sequential)  (None, 5)                 525829    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58857477 (224.52 MB)\n",
      "Trainable params: 525829 (2.01 MB)\n",
      "Non-trainable params: 58331648 (222.52 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_resnet152_model(input_shape, num_classes):\n",
    "    # Load pre-trained ResNet152V2 model without the top classification layer\n",
    "    base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze the weights of the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom classification head\n",
    "    top_layers = models.Sequential([\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Combine the base model with custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        top_layers\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Input shape for ResNet152V2\n",
    "num_classes = train_annotations['label'].nunique()  # Example number of output classes\n",
    "\n",
    "# Create the ResNet152 model\n",
    "resnet152_model = create_resnet152_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "resnet152_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "resnet152_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=10, batch_size=32)\n",
    "\n",
    "# Print model summary\n",
    "resnet152_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 46s 3s/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Vehiculos       0.00      0.00      0.00         3\n",
      "Construcciones       0.82      1.00      0.90       254\n",
      "          Vias       0.86      0.51      0.64        98\n",
      "          Rios       0.98      0.85      0.91        60\n",
      "       Mineria       0.40      0.22      0.29         9\n",
      "\n",
      "      accuracy                           0.84       424\n",
      "     macro avg       0.61      0.52      0.55       424\n",
      "  weighted avg       0.84      0.84      0.82       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   3   0   0   0]\n",
      " [  0 253   0   0   1]\n",
      " [  0  46  50   1   1]\n",
      " [  0   0   8  51   1]\n",
      " [  0   7   0   0   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(resnet152_model.predict(X_val), axis=1)\n",
    "\n",
    "y_val_label = np.array(y_val_label, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "target_names = ['Vehiculos', 'Construcciones', 'Vias', 'Rios', 'Mineria']  # Get unique class labels\n",
    "print(classification_report(y_val_label, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_label, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
