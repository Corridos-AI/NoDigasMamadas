{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to transform our labels data set into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each label file in the labels folder\n",
    "def create_csv_annotations(images_folder, labels_folder, name):\n",
    "    annotations = []\n",
    "    image_width = 300\n",
    "    image_height = 300\n",
    "\n",
    "    for label_file in os.listdir(labels_folder):\n",
    "        if label_file.endswith('.txt'):\n",
    "            with open(os.path.join(labels_folder, label_file), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            image_name = os.path.splitext(label_file)[0] + '.jpg'\n",
    "            image_path = os.path.join(images_folder, image_name)\n",
    "            \n",
    "            for line in lines:\n",
    "                class_label, x_center, y_center, width, height = map(float, line.split())\n",
    "                x_min = (x_center - width / 2)\n",
    "                y_min = (y_center - height / 2)\n",
    "                x_max = (x_center + width / 2)\n",
    "                y_max = (y_center + height / 2)\n",
    "                \n",
    "                annotations.append([image_path, x_min, y_min, x_max, y_max, image_width, image_height, class_label])\n",
    "\n",
    "        # Here we create a DataFrame from annotations list and then we convert the df into a csv file\n",
    "        df = pd.DataFrame(annotations, columns=['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'width', 'height', 'label'])\n",
    "        df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/train', 'labels/train', 'annotations_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/val', 'labels/val', 'annotations_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensor flow intro -> Why sequential](https://towardsdatascience.com/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa#:~:text=The%20sequential%20model%20allows%20us,for%20building%20deep%20learning%20models.)\n",
    "\n",
    "[Input and output shapes for CNN](https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca)\n",
    "\n",
    "[Basics of the R-CNN model](https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from CSV\n",
    "train_annotations = pd.read_csv('annotations_train.csv')\n",
    "val_annotations = pd.read_csv('annotations_val.csv')\n",
    "\n",
    "#train_annotations, val_annotations = train_test_split(annotations, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_shape = (224, 224, 3)  # height, width, depth (this is the # of color channels RGB = 3)\n",
    "\n",
    "# Function to preprocess image and annotations -> this is because \n",
    "# the annotations are still not in the format required for TF\n",
    "def preprocess_data(annotation):\n",
    "    image = load_img(annotation['img_path'], target_size=(input_shape[0], input_shape[1]))\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    bbox = [annotation['xmin'], annotation['ymin'], annotation['xmax'], annotation['ymax']]\n",
    "    label = annotation['label']\n",
    "    return image_array, bbox, label\n",
    "\n",
    "train_data = train_annotations.apply(preprocess_data, axis=1)\n",
    "val_data = val_annotations.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Convert preprocessed data into arrays -> this is the format needed for TF\n",
    "X_train, y_train_bbox, y_train_label = zip(*train_data)\n",
    "X_val, y_val_bbox, y_val_label = zip(*val_data)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train_bbox = tf.convert_to_tensor(y_train_bbox)\n",
    "y_train_label = tf.convert_to_tensor(y_train_label)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "y_val_bbox = tf.convert_to_tensor(y_val_bbox)\n",
    "y_val_label = tf.convert_to_tensor(y_val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the RCNN model, this is just base model for testing\n",
    "def create_rcnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),#batch_input_shape (if you wanted to give the batch_size)\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(), # Here we are basically changing the 4D output of the CNN to 2D so that we can use Dense\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax', name='classifier_output')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Number of classes\n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "# Create an instance of the R-CNN model\n",
    "rcnn_model = create_rcnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with appropriate losses and metrics\n",
    "rcnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "rcnn_model.fit(X_train, y_train_label, validation_data=(X_val, y_val_label), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 50s 2s/step - loss: 1.6207 - accuracy: 0.4053 - val_loss: 1.7242 - val_accuracy: 0.1714\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 43s 2s/step - loss: 1.3250 - accuracy: 0.4627 - val_loss: 1.8089 - val_accuracy: 0.1714\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 40s 2s/step - loss: 1.2953 - accuracy: 0.4733 - val_loss: 1.6119 - val_accuracy: 0.1714\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 40s 2s/step - loss: 1.2523 - accuracy: 0.4827 - val_loss: 1.5452 - val_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 42s 2s/step - loss: 1.2162 - accuracy: 0.4653 - val_loss: 1.6070 - val_accuracy: 0.0714\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 41s 2s/step - loss: 1.1939 - accuracy: 0.5027 - val_loss: 1.5302 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 42s 2s/step - loss: 1.1070 - accuracy: 0.5267 - val_loss: 1.4683 - val_accuracy: 0.4143\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 41s 2s/step - loss: 1.0843 - accuracy: 0.5453 - val_loss: 1.4992 - val_accuracy: 0.2429\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 41s 2s/step - loss: 1.0411 - accuracy: 0.5493 - val_loss: 1.5227 - val_accuracy: 0.2714\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 41s 2s/step - loss: 0.9917 - accuracy: 0.5747 - val_loss: 1.5935 - val_accuracy: 0.2857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x198756bde50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_rcnn_resnet(input_shape, num_classes):\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Additional convolutional layers with reduced kernel size\n",
    "    conv_layers = models.Sequential([ #Without the padding / strides I get dimensionality errors :(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),  # Reduce the pooling stride\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),  # Reduce the pooling stride\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "    ])\n",
    "    \n",
    "    # R-CNN top layers\n",
    "    top_layers = models.Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax', name='classifier_output')\n",
    "    ])\n",
    "    \n",
    "    # Combine the base ResNet model, additional convolutional layers, and top layers\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        conv_layers,\n",
    "        top_layers\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Number of classes\n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "input_shape = (224, 224, 3)  # 224 is the one used by ResNet\n",
    "rcnn_resnet_model = create_rcnn_resnet(input_shape, num_classes)\n",
    "\n",
    "rcnn_resnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rcnn_resnet_model.fit(X_train, y_train_label, validation_data=(X_val, y_val_label), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 5s 1s/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Vehiculos       0.00      0.00      0.00        13\n",
      "Construcciones       0.24      1.00      0.39        13\n",
      "          Vias       0.47      0.23      0.31        30\n",
      "          Rios       0.00      0.00      0.00        12\n",
      "       Mineria       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.29        70\n",
      "     macro avg       0.14      0.25      0.14        70\n",
      "  weighted avg       0.24      0.29      0.21        70\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 13  0  0  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0 22  7  1  0]\n",
      " [ 0  4  8  0  0]\n",
      " [ 0  2  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(rcnn_resnet_model.predict(X_val), axis=1)\n",
    "\n",
    "y_val_label = np.array(y_val_label, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "target_names = ['Vehiculos', 'Construcciones', 'Vias', 'Rios', 'Mineria']  # Get unique class labels\n",
    "print(classification_report(y_val_label, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_label, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.0' '2.0' '1.0' '4.0' '0.0']\n"
     ]
    }
   ],
   "source": [
    "print(target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
