{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating annotations\n",
    "First we need to transform our Yolo labels dataset into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each label file in the labels folder\n",
    "def create_csv_annotations(images_folder, labels_folder, name):\n",
    "    annotations = []\n",
    "    image_width = 224\n",
    "    image_height = 224\n",
    "\n",
    "    for label_file in os.listdir(labels_folder):\n",
    "        if label_file.endswith('.txt'):\n",
    "            with open(os.path.join(labels_folder, label_file), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            image_name = os.path.splitext(label_file)[0] + '.jpg'\n",
    "            image_path = os.path.join(images_folder, image_name)\n",
    "            \n",
    "            for line in lines:\n",
    "                class_label, x_center, y_center, width, height = map(float, line.split())\n",
    "                x_min = (x_center - width / 2)\n",
    "                y_min = (y_center - height / 2)\n",
    "                x_max = (x_center + width / 2)\n",
    "                y_max = (y_center + height / 2)\n",
    "                \n",
    "                annotations.append([image_path, x_min, y_min, x_max, y_max, image_width, image_height, class_label])\n",
    "\n",
    "        # Here we create a DataFrame from annotations list and then we convert the df into a csv file\n",
    "        df = pd.DataFrame(annotations, columns=['img_path', 'xmin', 'ymin', 'xmax', 'ymax', 'width', 'height', 'label'])\n",
    "        df.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/train', 'labels/train', 'annotations_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/test', 'labels/test', 'annotations_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_annotations('images/val', 'labels/val', 'annotations_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the csv annotations to arrays required by TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from CSV\n",
    "train_annotations = pd.read_csv('annotations_train.csv')\n",
    "val_annotations = pd.read_csv('annotations_val.csv')\n",
    "test_annotations = pd.read_csv('annotations_test.csv')\n",
    "\n",
    "#train_annotations, val_annotations = train_test_split(annotations, test_size=0.2, random_state=42)\n",
    "\n",
    "# The 224 x 224 input is required because -> this is because vast majority of pretrained TF models\n",
    "# were trained using that input\n",
    "input_shape = (224, 224, 3)  # height, width, depth (this is the # of color channels RGB = 3)\n",
    "\n",
    "# Function to preprocess image and annotations\n",
    "# the annotations are still not in the format required for TF\n",
    "def preprocess_data(annotation):\n",
    "    image = load_img(annotation['img_path'], target_size=(input_shape[0], input_shape[1]))\n",
    "    image_array = img_to_array(image)\n",
    "    image_array /= 255.0\n",
    "    bbox = [annotation['xmin'], annotation['ymin'], annotation['xmax'], annotation['ymax']]\n",
    "    label = annotation['label']\n",
    "    return image_array, bbox, label\n",
    "\n",
    "train_data = train_annotations.apply(preprocess_data, axis=1)\n",
    "val_data = val_annotations.apply(preprocess_data, axis=1)\n",
    "test_data = test_annotations.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Convert preprocessed data into arrays -> this is the format needed for TF\n",
    "X_train, y_train_bbox, y_train_label = zip(*train_data)\n",
    "X_val, y_val_bbox, y_val_label = zip(*val_data)\n",
    "X_test, y_test_bbox, y_test_label = zip(*test_data)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train_bbox = tf.convert_to_tensor(y_train_bbox)\n",
    "y_train_label = tf.convert_to_tensor(y_train_label)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "y_val_bbox = tf.convert_to_tensor(y_val_bbox)\n",
    "y_val_label = tf.convert_to_tensor(y_val_label)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test_bbox = tf.convert_to_tensor(y_test_bbox)\n",
    "y_test_label = tf.convert_to_tensor(y_test_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are checking that the shapes of the images[0] and labels are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2776"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2776, 224, 224, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2776,), dtype=float32, numpy=array([3., 3., 3., ..., 2., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([859])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts to wrap your head around the next models\n",
    "\n",
    "[Tensor flow intro -> Why sequential](https://towardsdatascience.com/a-comprehensive-introduction-to-tensorflows-sequential-api-and-model-for-deep-learning-c5e31aee49fa#:~:text=The%20sequential%20model%20allows%20us,for%20building%20deep%20learning%20models.): Here we have a more in depth explanation of what we are actually doing when adding layers to the model.Sequential and what that means. All of the following models work based on that cause we are training neural networks.\n",
    "\n",
    "[Input and output shapes for CNN](https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca): This can help you understand why the value behind our input_shape and a bit more about the CNNs\n",
    "\n",
    "[Types of Convolutions in Deep Learning](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d): Here we have some types of convolutions used by some of the next models. For example, MobileNetV2 uses depthwise separable convolutions, and those are explained here.\n",
    "\n",
    "[But What is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA):\n",
    "In case you really want to understand the basics and what a convolution really is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model\n",
    "\n",
    "[Basics of the R-CNN model](https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the RCNN model, this is just base model for testing\n",
    "def create_rcnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),#batch_input_shape (if you wanted to give the batch_size)\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(), # Here we are basically changing the 4D output of the CNN to 2D so that we can use Dense\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax', name='classifier_output')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Number of classes\n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "# Create an instance of the R-CNN model\n",
    "rcnn_model = create_rcnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with appropriate losses and metrics\n",
    "rcnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "rcnn_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCNN With MobileNetV2\n",
    "\n",
    "[What is MobileNetV2](https://towardsdatascience.com/mobilenetv2-inverted-residuals-and-linear-bottlenecks-8a4362f4ffd5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "87/87 [==============================] - 277s 3s/step - loss: 0.7821 - accuracy: 0.7003 - val_loss: 1.1293 - val_accuracy: 0.6752\n",
      "Epoch 2/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.6065 - accuracy: 0.7720 - val_loss: 0.9024 - val_accuracy: 0.6822\n",
      "Epoch 3/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.6084 - accuracy: 0.7622 - val_loss: 3.2185 - val_accuracy: 0.1281\n",
      "Epoch 4/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.5777 - accuracy: 0.7741 - val_loss: 1.2873 - val_accuracy: 0.2352\n",
      "Epoch 5/15\n",
      "87/87 [==============================] - 260s 3s/step - loss: 0.5349 - accuracy: 0.7878 - val_loss: 1.9865 - val_accuracy: 0.2421\n",
      "Epoch 6/15\n",
      "87/87 [==============================] - 257s 3s/step - loss: 0.5108 - accuracy: 0.7947 - val_loss: 3.5161 - val_accuracy: 0.3725\n",
      "Epoch 7/15\n",
      "87/87 [==============================] - 256s 3s/step - loss: 0.5183 - accuracy: 0.7918 - val_loss: 0.9597 - val_accuracy: 0.6694\n",
      "Epoch 8/15\n",
      "87/87 [==============================] - 270s 3s/step - loss: 0.5351 - accuracy: 0.7932 - val_loss: 1.0858 - val_accuracy: 0.5588\n",
      "Epoch 9/15\n",
      "87/87 [==============================] - 270s 3s/step - loss: 0.5175 - accuracy: 0.7885 - val_loss: 3.3442 - val_accuracy: 0.2875\n",
      "Epoch 10/15\n",
      "87/87 [==============================] - 249s 3s/step - loss: 0.4931 - accuracy: 0.7929 - val_loss: 3.3598 - val_accuracy: 0.1153\n",
      "Epoch 11/15\n",
      "87/87 [==============================] - 251s 3s/step - loss: 0.5413 - accuracy: 0.7885 - val_loss: 1.5074 - val_accuracy: 0.2887\n",
      "Epoch 12/15\n",
      "87/87 [==============================] - 247s 3s/step - loss: 0.4938 - accuracy: 0.8015 - val_loss: 1.4249 - val_accuracy: 0.1804\n",
      "Epoch 13/15\n",
      "87/87 [==============================] - 245s 3s/step - loss: 0.4745 - accuracy: 0.7983 - val_loss: 0.8281 - val_accuracy: 0.6787\n",
      "Epoch 14/15\n",
      "87/87 [==============================] - 246s 3s/step - loss: 0.4624 - accuracy: 0.8069 - val_loss: 1.0161 - val_accuracy: 0.5565\n",
      "Epoch 15/15\n",
      "87/87 [==============================] - 245s 3s/step - loss: 0.4389 - accuracy: 0.8102 - val_loss: 0.8252 - val_accuracy: 0.7218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x140f2773400>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_rcnn_MovileNetV2(input_shape, num_classes):\n",
    "    \n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    \n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Additional convolutional layers with reduced kernel size\n",
    "    conv_layers = models.Sequential([ #Without the padding / strides I get dimensionality errors :(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),  # Reduce the pooling stride\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),  # Reduce the pooling stride\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Add padding to maintain spatial dimensions\n",
    "    ])\n",
    "    \n",
    "    # R-CNN top layers\n",
    "    top_layers = models.Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax', name='classifier_output')\n",
    "    ])\n",
    "    \n",
    "    # Combine the base ResNet model, additional convolutional layers, and top layers\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        conv_layers,\n",
    "        top_layers\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Number of classes\n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "input_shape = (224, 224, 3)  # 224 is the one used by ResNet\n",
    "rcnn_resnet_model = create_rcnn_MovileNetV2(input_shape, num_classes)\n",
    "\n",
    "rcnn_resnet_model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rcnn_resnet_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 7s 525ms/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Vehiculos       0.00      0.00      0.00         3\n",
      "Construcciones       0.80      0.93      0.86       254\n",
      "          Vias       0.73      0.39      0.51        98\n",
      "          Rios       0.67      0.83      0.74        60\n",
      "       Mineria       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.77       424\n",
      "     macro avg       0.44      0.43      0.42       424\n",
      "  weighted avg       0.74      0.77      0.74       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   3   0]\n",
      " [  0 237   5  12   0]\n",
      " [  0  55  38   5   0]\n",
      " [  0   3   7  50   0]\n",
      " [  0   2   2   5   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(rcnn_resnet_model.predict(X_val), axis=1)\n",
    "\n",
    "y_val_label = np.array(y_val_label, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "target_names = ['Vehiculos', 'Construcciones', 'Vias', 'Rios', 'Mineria']  # Get unique class labels\n",
    "print(classification_report(y_val_label, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_label, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet152\n",
    "This one is the deepest variant of ResNet providing 152 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 392s 4s/step - loss: 0.8008 - accuracy: 0.7082 - val_loss: 0.5171 - val_accuracy: 0.7939\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 369s 4s/step - loss: 0.5806 - accuracy: 0.7677 - val_loss: 0.4816 - val_accuracy: 0.8044\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 373s 4s/step - loss: 0.5310 - accuracy: 0.7914 - val_loss: 0.5054 - val_accuracy: 0.8079\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 373s 4s/step - loss: 0.5063 - accuracy: 0.7968 - val_loss: 0.4566 - val_accuracy: 0.8091\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 371s 4s/step - loss: 0.4873 - accuracy: 0.7979 - val_loss: 0.4525 - val_accuracy: 0.8102\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 372s 4s/step - loss: 0.4576 - accuracy: 0.8030 - val_loss: 0.4564 - val_accuracy: 0.7986\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 371s 4s/step - loss: 0.4548 - accuracy: 0.8098 - val_loss: 0.4470 - val_accuracy: 0.8114\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 371s 4s/step - loss: 0.4509 - accuracy: 0.8062 - val_loss: 0.4415 - val_accuracy: 0.8114\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 374s 4s/step - loss: 0.4480 - accuracy: 0.8105 - val_loss: 0.4328 - val_accuracy: 0.8137\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 373s 4s/step - loss: 0.4358 - accuracy: 0.8134 - val_loss: 0.4413 - val_accuracy: 0.8114\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 7, 7, 2048)        58331648  \n",
      "                                                                 \n",
      " sequential_11 (Sequential)  (None, 5)                 525829    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58857477 (224.52 MB)\n",
      "Trainable params: 525829 (2.01 MB)\n",
      "Non-trainable params: 58331648 (222.52 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_resnet152_model(input_shape, num_classes):\n",
    "    # Load pre-trained ResNet152V2 model without the top classification layer\n",
    "    base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze the weights of the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom classification head\n",
    "    top_layers = models.Sequential([\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Combine the base model with custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        top_layers\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3)  # Input shape for ResNet152V2\n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "# Create the ResNet152 model\n",
    "resnet152_model = create_resnet152_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "resnet152_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "resnet152_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=10, batch_size=32)\n",
    "\n",
    "# Print model summary\n",
    "resnet152_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 46s 3s/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Vehiculos       0.00      0.00      0.00         3\n",
      "Construcciones       0.82      1.00      0.90       254\n",
      "          Vias       0.86      0.51      0.64        98\n",
      "          Rios       0.98      0.85      0.91        60\n",
      "       Mineria       0.40      0.22      0.29         9\n",
      "\n",
      "      accuracy                           0.84       424\n",
      "     macro avg       0.61      0.52      0.55       424\n",
      "  weighted avg       0.84      0.84      0.82       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   3   0   0   0]\n",
      " [  0 253   0   0   1]\n",
      " [  0  46  50   1   1]\n",
      " [  0   0   8  51   1]\n",
      " [  0   7   0   0   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(resnet152_model.predict(X_val), axis=1)\n",
    "\n",
    "y_val_label = np.array(y_val_label, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "target_names = ['Vehiculos', 'Construcciones', 'Vias', 'Rios', 'Mineria']  # Get unique class labels\n",
    "print(classification_report(y_val_label, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_label, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.tfkeras import EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 500s 5s/step - loss: 0.7760 - accuracy: 0.6985 - val_loss: 0.5469 - val_accuracy: 0.7707\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 464s 5s/step - loss: 0.6127 - accuracy: 0.7579 - val_loss: 0.4963 - val_accuracy: 0.8021\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 458s 5s/step - loss: 0.5841 - accuracy: 0.7684 - val_loss: 0.4788 - val_accuracy: 0.7893\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 458s 5s/step - loss: 0.5671 - accuracy: 0.7759 - val_loss: 0.4654 - val_accuracy: 0.7986\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 460s 5s/step - loss: 0.5352 - accuracy: 0.7767 - val_loss: 0.4644 - val_accuracy: 0.8114\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 457s 5s/step - loss: 0.5342 - accuracy: 0.7857 - val_loss: 0.4719 - val_accuracy: 0.7998\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 463s 5s/step - loss: 0.5195 - accuracy: 0.7885 - val_loss: 0.4472 - val_accuracy: 0.8184\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 462s 5s/step - loss: 0.5022 - accuracy: 0.8001 - val_loss: 0.4466 - val_accuracy: 0.8114\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 467s 5s/step - loss: 0.5148 - accuracy: 0.7903 - val_loss: 0.4360 - val_accuracy: 0.8196\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 462s 5s/step - loss: 0.5021 - accuracy: 0.7957 - val_loss: 0.4297 - val_accuracy: 0.8102\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnet-b6 (Functiona  (None, 7, 7, 2304)        40960136  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " sequential_21 (Sequential)  (None, 5)                 591365    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41551501 (158.51 MB)\n",
      "Trainable params: 591365 (2.26 MB)\n",
      "Non-trainable params: 40960136 (156.25 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_b6(input_shape, num_classes):\n",
    "    # Load pre-trained EfficientNet-B6 model without the top classification layer\n",
    "    base_model = EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #  Custom classification head\n",
    "    top_layers = models.Sequential([\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Here we combine the base model with our custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        top_layers\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3)  # Input shape for EfficientNet-B6\n",
    "num_classes = train_annotations['label'].nunique() \n",
    "\n",
    "# Create the EfficientNet-B6 model\n",
    "efficientnet_b6_model = create_efficientnet_b6(input_shape, num_classes)\n",
    "\n",
    "# Compile the model - sparse_cc instead of cc is needed otherwise I get ValueError: Shapes (None, 1) and (None, 5) are incompatible\n",
    "efficientnet_b6_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "efficientnet_b6_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "efficientnet_b6_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 61s 4s/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Vehiculos       0.40      0.67      0.50         3\n",
      "Construcciones       0.82      0.98      0.89       254\n",
      "          Vias       0.84      0.50      0.63        98\n",
      "          Rios       0.93      0.90      0.92        60\n",
      "       Mineria       0.50      0.11      0.18         9\n",
      "\n",
      "      accuracy                           0.83       424\n",
      "     macro avg       0.70      0.63      0.62       424\n",
      "  weighted avg       0.83      0.83      0.82       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  2   1   0   0   0]\n",
      " [  2 248   3   0   1]\n",
      " [  0  45  49   4   0]\n",
      " [  0   1   5  54   0]\n",
      " [  1   6   1   0   1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(efficientnet_b6_model.predict(X_val), axis=1)\n",
    "\n",
    "y_val_label = np.array(y_val_label, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "target_names = ['Vehiculos', 'Construcciones', 'Vias', 'Rios', 'Mineria']  # Get unique class labels\n",
    "print(classification_report(y_val_label, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_label, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 343s 4s/step - loss: 0.7905 - accuracy: 0.7061 - val_loss: 0.5361 - val_accuracy: 0.8033\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 326s 4s/step - loss: 0.5888 - accuracy: 0.7677 - val_loss: 0.5133 - val_accuracy: 0.7905\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 330s 4s/step - loss: 0.5415 - accuracy: 0.7770 - val_loss: 0.4785 - val_accuracy: 0.8079\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 331s 4s/step - loss: 0.5105 - accuracy: 0.7947 - val_loss: 0.4587 - val_accuracy: 0.8079\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 332s 4s/step - loss: 0.4974 - accuracy: 0.7929 - val_loss: 0.4375 - val_accuracy: 0.8219\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 332s 4s/step - loss: 0.4942 - accuracy: 0.8012 - val_loss: 0.4583 - val_accuracy: 0.8102\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 327s 4s/step - loss: 0.4748 - accuracy: 0.8069 - val_loss: 0.4257 - val_accuracy: 0.8219\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 329s 4s/step - loss: 0.4664 - accuracy: 0.8134 - val_loss: 0.4331 - val_accuracy: 0.8149\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 330s 4s/step - loss: 0.4656 - accuracy: 0.8044 - val_loss: 0.4312 - val_accuracy: 0.8196\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 331s 4s/step - loss: 0.4440 - accuracy: 0.8066 - val_loss: 0.4369 - val_accuracy: 0.8196\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " sequential_23 (Sequential)  (None, 5)                 986117    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19308101 (73.65 MB)\n",
      "Trainable params: 986117 (3.76 MB)\n",
      "Non-trainable params: 18321984 (69.89 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_densenet_264(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.DenseNet201(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom classification head\n",
    "    top_layers = models.Sequential([\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        top_layers\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3) \n",
    "num_classes = train_annotations['label'].nunique()\n",
    "\n",
    "# Create the DenseNet-264 model\n",
    "densenet_264_model = create_densenet_264(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "densenet_264_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "densenet_264_model.fit(X_train, y_train_label, validation_data=(X_test, y_test_label), epochs=10, batch_size=32)\n",
    "\n",
    "densenet_264_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 44s 3s/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Vehiculos       0.00      0.00      0.00         3\n",
      "Construcciones       0.80      0.98      0.88       254\n",
      "          Vias       0.89      0.41      0.56        98\n",
      "          Rios       0.93      0.90      0.92        60\n",
      "       Mineria       0.55      0.67      0.60         9\n",
      "\n",
      "      accuracy                           0.82       424\n",
      "     macro avg       0.63      0.59      0.59       424\n",
      "  weighted avg       0.83      0.82      0.80       424\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0   3   0   0   0]\n",
      " [  0 249   0   0   5]\n",
      " [  0  54  40   4   0]\n",
      " [  0   1   5  54   0]\n",
      " [  0   3   0   0   6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\juank\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = np.argmax(densenet_264_model.predict(X_val), axis=1)\n",
    "\n",
    "y_val_label = np.array(y_val_label, dtype=int)\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "\n",
    "target_names = ['Vehiculos', 'Construcciones', 'Vias', 'Rios', 'Mineria']  # Get unique class labels\n",
    "print(classification_report(y_val_label, y_pred, target_names=target_names))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_label, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reshaped = y_pred.reshape(-1, 1) \n",
    "conf_scores = np.max(y_pred_reshaped, axis=1)  \n",
    "\n",
    "sorted_indices = np.argsort(conf_scores)[::-1]\n",
    "sorted_conf_scores = conf_scores[sorted_indices]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for class_label in range(5):\n",
    "    class_precisions = []\n",
    "    class_recalls = []\n",
    "    for threshold in sorted_conf_scores:\n",
    "        threshold_mask = conf_scores >= threshold\n",
    "        y_pred_threshold = y_pred_reshaped[threshold_mask]\n",
    "        y_true_threshold = y_val_label[threshold_mask]\n",
    "        precision = precision_score(y_true_threshold == class_label, y_pred_threshold == class_label)\n",
    "        recall = recall_score(y_true_threshold == class_label, y_pred_threshold == class_label)\n",
    "        class_precisions.append(precision)\n",
    "        class_recalls.append(recall)\n",
    "    \n",
    "    precisions.append(class_precisions)\n",
    "    recalls.append(class_recalls)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for class_label in range(5):\n",
    "    plt.plot(recalls[class_label], precisions[class_label], label=f'Class {class_label}')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for Each Class')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
